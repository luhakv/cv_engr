{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Module3_final_task_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peKwOLXOwes_"
      },
      "source": [
        "Давайте с вами решим многоклассовую задачу, но теперь с использованием более верхнеуровневого фреймворка PyTorch.\n",
        "\n",
        "Для этого мы возьмём датасет MNIST. Он очень похож на Digits из предыдущего задания и тоже содержит черно-белые рукописные цифры от 0 до 9, только размер уже 28х28 пикселей.\n",
        "\n",
        "Вообще, MNIST — знаковый датасет для глубокого обучения, именно для него Yahn LeCun разработал первую свёрточную нейросеть LeNet и применил для её обучения механизм обратного распространения ошибки, что дало сильный толчок в развитии нейронных сетей и глубокого обучения в целом."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8kPwjr1yTQx"
      },
      "source": [
        "В этом задании вам придется много опираться на ноутбук ipynb, в котором мы знакомились с основными элементами PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ2UERTwkkUf"
      },
      "source": [
        "# Финальное задание PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wb7nZCNfiHvX"
      },
      "source": [
        "Начнем с основных импортов и определения констант - доступного девайса для вычислений и параметров, которые зависят от выборки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVmBHU5edzqN"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# выбор девайса\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# параметры, которые зависят от нашего датасета\n",
        "input_size = 784\n",
        "num_classes = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZDEIQ1JiVXm"
      },
      "source": [
        "Предлагаем вам попробовать выбрать самим гиперпараметры обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id0sYfupd20V"
      },
      "source": [
        "# выберите сами данные параметры\n",
        "num_epochs = # место для вашего кода\n",
        "batch_size = # место для вашего кода\n",
        "learning_rate = # место для вашего кода"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnootprMixZm"
      },
      "source": [
        "Загружаем датасет MNIST - он есть в стандартном наборе датасетов pytorch, выбираем transform=ToTensor(), это важно!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKVuwQcqd5Ql"
      },
      "source": [
        "# MNIST dataset \n",
        "train_dataset = torchvision.datasets.MNIST(root='../../data', \n",
        "                                           train=True, \n",
        "                                           transform=transforms.ToTensor(),  \n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='../../data', \n",
        "                                          train=False, \n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# transform.ToTensor() записывает данные в torch.tensor и нормализовывает данные,\n",
        "# разделяя значения каждого пикселя на 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipgirQxSjKWG"
      },
      "source": [
        "Настраиваем dataloader - объект, который датасет "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06yWRBfWjIfV"
      },
      "source": [
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD-iGbicd9FM"
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        # сконструируйте свою сеть, опишите слои, которые будут использоваться\n",
        "        # достаточно будет двух линейных слоев с ReLU после первого,\n",
        "        # но мы оставляем этот выбор вам, можно составить любую сеть\n",
        "        # SoftMax указывать не нужно \n",
        "    \n",
        "    def forward(self, x):\n",
        "        # опишите функцию forward, то есть проход по вашей сети\n",
        "        # результат применения x к первому слою отдайте на вход функции активации\n",
        "        # выход функции активации отправьте на вход следущему слою и так далее\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, num_classes).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBBvPF5ieAV0"
      },
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "# в качестве функции потерь используем Cross Entropy\n",
        "# в PyTorch кросс энтропия реализована с помощью LogSoftmax и \n",
        "# Negative Log Likelyhood loss, что на самом деле даёт такой же результат\n",
        "# Так как мы не указали внутри сети SoftMax и он учтен только в Loss функции,\n",
        "# при тестировании сети нам нужно учесть этот факт и руками интерпретировать выход сети\n",
        "\n",
        "\n",
        "optimizer = torch.optim.# выберите оптимизатор (вариантов много - SGD, AdaGrad, Adam, RMSProp и т.д.)\n",
        "# параметры для оптимизатора, передайте в скобках в предыдущей строке(model.parameters(), lr=learning_rate)  \n",
        "# почитать про оптимизаторы можно тут https://pytorch.org/docs/stable/optim.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaAOxTqKeDXM"
      },
      "source": [
        "# Train\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    # получаем батч\n",
        "    for i, (images, labels) in enumerate(train_loader):  \n",
        "        # запишем данные в строку\n",
        "        images = images.reshape(# подберите размер ).to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backprpagation and optimization\n",
        "        optimizer.zero_grad()\n",
        "        # считаем градиенты\n",
        "        loss.backward()\n",
        "        # обновляем параметры\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlnDk3TkrYS2"
      },
      "source": [
        "\n",
        "\n",
        "# test\n",
        "# так как мы не использовали софтмакс, то берем максимум от выхода сети\n",
        "# и считаем что индекс этого класса и есть наш ответ\n",
        "# для интерпретируемости можно при тестировании добавить SM на выход\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(# подберите размер).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84TJdPOd4tku"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "batch_counter = 0\n",
        "\n",
        "total = 0\n",
        "correct = 0\n",
        "for images, labels in test_loader:\n",
        "\n",
        "    images_flat = images.reshape(-1, 28 * 28).to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images_flat)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    # отрисуем несколько примеров и выведем наши ответы на них\n",
        "    if (batch_counter < 3):\n",
        "        plt.figure(batch_counter)\n",
        "        plt.imshow(images[0][0])\n",
        "        print(predicted.data[0])\n",
        "    batch_counter += 1\n",
        "\n",
        "print(\"Test accuracy is {}\".format(100 * correct/total))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scXJ6C_XE4fm"
      },
      "source": [
        "Если точность на тесте больше 0.8 — поздравляем с выполнением задания!"
      ]
    }
  ]
}