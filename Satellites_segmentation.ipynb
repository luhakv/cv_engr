{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Satellites_segmentation",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCDcE_zSQ2ye"
      },
      "source": [
        "#Сегментация космических объектов \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q0ZfqmjT8VJ"
      },
      "source": [
        "## Загрузка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APg9y9gCZ_8h"
      },
      "source": [
        "Для комфортной хагрузки данных добавьте ярлык папки Final_dataset (https://drive.google.com/drive/u/0/folders/1Q1wR9aBFCyeFEYa3wwyXNu9wk_fZdzUm) к себе на диск."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eFeELOmZBCJ",
        "outputId": "86b0377c-cbd5-4ad3-b469-31e24194eacc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vl9kyOxaVf8",
        "outputId": "b631f52e-d80a-443f-ddf5-ceffd8d9d7fa"
      },
      "source": [
        "!ls drive/MyDrive/Final_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all_bbox.txt  images  mask  ReadMe.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_nIQ-L0aXfi"
      },
      "source": [
        "images_path = 'drive/MyDrive/Final_dataset/images/'\n",
        "mask_path = 'drive/MyDrive/Final_dataset/mask/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5g-TGxWGa2WP"
      },
      "source": [
        "## Импортируем нужные библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvbnjzfhayLT"
      },
      "source": [
        "%%capture out\n",
        "!pip install albumentations torchmetrics pytorch_lightning -U"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SePCyDfIa4jg"
      },
      "source": [
        "import os\n",
        "\n",
        "import albumentations as A\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchmetrics\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "from pytorch_lightning.callbacks import (\n",
        "    EarlyStopping,\n",
        "    LearningRateMonitor,\n",
        "    ModelCheckpoint,\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm.auto import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wU3FnCgaa6MS"
      },
      "source": [
        "class SattDataset(Dataset):\n",
        "    def __init__(self, split=\"train\", transform=None):\n",
        "        self.images_filenames = os.listdir(images_path + split) \n",
        "        self.mask_filenames = os.listdir(mask_path + split)       \n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images_filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #Ваш код здесь"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOUpqS--ceXB"
      },
      "source": [
        "train_dataset = SattDataset()\n",
        "val_dataset = SattDataset(split=\"val\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPcDHM3WclL0"
      },
      "source": [
        "def display_few_examples_from_data(dataset, n=4):\n",
        "    #Ваш код здесь"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffgl58_agAqX"
      },
      "source": [
        "### Выбираем аугментации для обучения\n",
        "\n",
        "Вы можете заменить аугментацию на ваш выбор"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUfbLt-ocir2"
      },
      "source": [
        "train_transform = A.Compose(\n",
        "    [\n",
        "        A.Resize(512, 512),\n",
        "        A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=0.5),\n",
        "        A.RGBShift(r_shift_limit=25, g_shift_limit=25, b_shift_limit=25, p=0.5),\n",
        "        A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")\n",
        "train_dataset = SattDataset(\n",
        "    \"train\",\n",
        "    transform=train_transform,\n",
        ")\n",
        "\n",
        "val_transform = A.Compose(\n",
        "    [\n",
        "        A.Resize(512, 512)\n",
        "    ]   A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)), ToTensorV2()]\n",
        ")\n",
        "val_dataset = SattDataset(\"Val\", transform=train_transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyEORi6NgPR5"
      },
      "source": [
        "display_few_examples_from_data(train_dataset)\n",
        "print(\"Validation dataset\")\n",
        "display_few_examples_from_data(val_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSflLGXVgW5L"
      },
      "source": [
        "## Обучение модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cryYC5Czgeqo"
      },
      "source": [
        " \n",
        "1.   Реализуйте выбранную вами модели instance segmentation\n",
        "2.   Обучите модель\n",
        "3.   Сравните разные метрики instance segmentation, включая mIoU\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lAxpkCbgRsJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}